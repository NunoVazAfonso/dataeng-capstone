{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load AWS Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('configs/global.cfg'))\n",
    "\n",
    "KEY = config.get('AWS', 'AWS_ACCESS_KEY_ID')\n",
    "SECRET = config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "OUTPUT_DATA = config.get('AWS','OUTPUT_DATA_FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= SECRET\n",
    "os.environ[\"AWS_DEFAULT_REGION\"]=\"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Set AWS clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr = boto3.client( 'emr', \n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET, \n",
    "                   region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2', \n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET, \n",
    "                   region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client( 's3', \n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET, \n",
    "                   region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.0.1 Upload flights URL list to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = [entry['Name'] for entry in s3.list_buckets()['Buckets'] if 'udacity' in entry['Name']  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload url lists of raw data to s3\n",
    "s3.upload_file( 'input/data/flights', s3_bucket[0], 'flights' )\n",
    "s3.upload_file( 'input/data/tweets', s3_bucket[0], 'tweets' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Create EMR instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_credentials_name = 'emr_udacity'\n",
    "instance_type = 'm5.xlarge'\n",
    "nr_slave_nodes = 2\n",
    "emr_name = 'udacity-capstone-' + time.strftime('%Y%m%d%H%M%S',time.gmtime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobFlowId': 'j-2CYW4R6S18ARG',\n",
       " 'ClusterArn': 'arn:aws:elasticmapreduce:us-west-2:794266340481:cluster/j-2CYW4R6S18ARG',\n",
       " 'ResponseMetadata': {'RequestId': '9aa34525-c7c3-427a-9410-ef569ca65247',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9aa34525-c7c3-427a-9410-ef569ca65247',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '118',\n",
       "   'date': 'Wed, 10 Mar 2021 09:35:33 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create EMR instance\n",
    "emr.run_job_flow(\n",
    "    Name=emr_name,\n",
    "    ReleaseLabel='emr-6.2.0',\n",
    "    Applications=[\n",
    "        {\n",
    "            'Name': 'Spark'\n",
    "        },\n",
    "    ],\n",
    "    Instances={\n",
    "        'InstanceGroups': [\n",
    "            {\n",
    "                'Name': \"Master nodes\",\n",
    "                'Market': 'ON_DEMAND',\n",
    "                'InstanceRole': 'MASTER',\n",
    "                'InstanceType': instance_type,\n",
    "                'InstanceCount': 1,\n",
    "            },\n",
    "            {\n",
    "                'Name': \"Slave nodes\",\n",
    "                'Market': 'ON_DEMAND',\n",
    "                'InstanceRole': 'CORE',\n",
    "                'InstanceType': instance_type,\n",
    "                'InstanceCount': nr_slave_nodes\n",
    "            }\n",
    "        ],\n",
    "        'Ec2KeyName': ec2_credentials_name,\n",
    "        'KeepJobFlowAliveWhenNoSteps': True\n",
    "    },\n",
    "    VisibleToAllUsers=True,\n",
    "    JobFlowRole='EMR_EC2_DefaultRole',\n",
    "    ServiceRole='EMR_DefaultRole'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching running EMR cluster: 1 try\n",
      "EMR Cluster found: udacity-capstone-20210310093530 waiting for job\n"
     ]
    }
   ],
   "source": [
    "# wait for emr created\n",
    "time.sleep( 60 * 5 )\n",
    "\n",
    "is_emr_started, nr_tries = False, 0\n",
    "\n",
    "emr_jobid = \"\"\n",
    "\n",
    "while not is_emr_started and nr_tries < 5:\n",
    "    print( \"Fetching running EMR cluster: {} try\".format( nr_tries + 1 ) )\n",
    "    \n",
    "    emr_list = emr.list_clusters()\n",
    "    \n",
    "    for cluster in emr_list['Clusters']:\n",
    "        if cluster['Name'] == emr_name and cluster['Status']['State'] == 'WAITING': \n",
    "            emr_jobid = cluster['Id']\n",
    "            is_emr_started = True\n",
    "            print( \"EMR Cluster found: {} waiting for job\".format(emr_name) )\n",
    "            break # waiting cluster found\n",
    "        elif cluster['Name'] == emr_name and 'TERMINATED' in cluster['Status']['State'] :\n",
    "            raise Exception('EMR cluster \\\"{}\\\" status was {}. '.format(cluster['Name'], cluster['Status']['State']) )        \n",
    "        else :\n",
    "            print(\"Retrying in 2 mins.\")\n",
    "            time.sleep(120)\n",
    "            \n",
    "    nr_tries+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add step to WAITING cluster\n",
    "# mount s3fs to waiting EMR\n",
    "# wget urls raw data\n",
    "response = emr.add_job_flow_steps(\n",
    "    JobFlowId = 'j-2CYW4R6S18ARG',\n",
    "    Steps=[\n",
    "        {\n",
    "            'Name': 'Mount s3fs and download files',\n",
    "            'ActionOnFailure': 'CANCEL_AND_WAIT',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 's3://us-west-2.elasticmapreduce/libs/script-runner/script-runner.jar',\n",
    "                'Args': [\n",
    "                    's3://udacity-awss/mount_s3fs.sh',\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add step to WAITING cluster\n",
    "# run spark job on raw data\n",
    "# ( see notebook 1.1 )\n",
    "response = emr.add_job_flow_steps(\n",
    "    JobFlowId = emr_jobid,\n",
    "    Steps=[\n",
    "        {\n",
    "            'Name': 'Run Spark for downloaded data',\n",
    "            'ActionOnFailure': 'CANCEL_AND_WAIT',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': [\n",
    "                    'spark-submit',\n",
    "                     '--deploy-mode',\n",
    "                     'cluster',\n",
    "                     '--master',\n",
    "                     'yarn',\n",
    "                     OUTPUT_DATA + 'etl.py'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr clusters: 1\n"
     ]
    }
   ],
   "source": [
    "# kill all clusters\n",
    "standby_clusters = emr.list_clusters( \n",
    "    ClusterStates=['RUNNING', 'WAITING'] \n",
    ")\n",
    "\n",
    "clusters = []\n",
    "for cluster in standby_clusters[\"Clusters\"] : \n",
    "    clusters.append( cluster[\"Id\"] )\n",
    "    \n",
    "print( \"Nr clusters: {}\".format( len(clusters) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating Clusters\n"
     ]
    }
   ],
   "source": [
    "if len(clusters) > 0 :\n",
    "    emr.terminate_job_flows(\n",
    "        JobFlowIds = clusters\n",
    "    )\n",
    "    print( \"Terminating Clusters\" )\n",
    "else: \n",
    "    print( \"No clusters found.\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
